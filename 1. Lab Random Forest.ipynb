{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f00890f",
   "metadata": {},
   "source": [
    "# Something to try some models out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6998229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moneycalc(confusion_matrix):\n",
    "    '''\n",
    "    This function takes a confusion matrix and calculates the cost of the sent mail\n",
    "    then it substracts it from the estimated revenue of the customers.\n",
    "    Cost of mail: 68 cents\n",
    "    Average donation: 15.62 $\n",
    "    '''\n",
    "    # Cost = 68 cents times all positive predicted, we will send the mail there\n",
    "    cost = 0.68 * (confusion_matrix[0][1]+confusion_matrix[1][1])\n",
    "    # Revenue = 15.62 * True positives\n",
    "    rev = 15.62 * confusion_matrix[1][1]\n",
    "    return rev-cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(X_train,X_test,y_train,y_test):\n",
    "    # Creating a list of different models\n",
    "    modellist = [LogisticRegression(random_state=0, solver='sag'),\n",
    "                 DecisionTreeClassifier(max_depth=2),\n",
    "                 neighbors.KNeighborsClassifier(n_neighbors=3, weights='distance'),\n",
    "                 RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.2,\n",
    "                             n_jobs = -1)  ]\n",
    "    modelnames = ['Logistic Regression','DecisionTree','KNN','RandomForest']\n",
    "    #Evaluating each model\n",
    "    for i in range(len(modellist)):\n",
    "        model = modellist[i]\n",
    "        # Fitting\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predicting\n",
    "        predictions = model.predict(X_test)\n",
    "        # Calculating confusion matrix\n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "        print(cm)\n",
    "        # Calculating profit if this prediction would have been apllied\n",
    "        print('Profit: '+str(moneycalc(cm))+ ' $')\n",
    "        # Printing different evaluation metrics\n",
    "        print(modelnames[i] + \" score: \", model.score(X_test, y_test))\n",
    "        print(modelnames[i] + \"precision: \",precision_score(y_test,predictions))\n",
    "        print(modelnames[i] + \"recall: \",recall_score(y_test,predictions))\n",
    "        print(modelnames[i] + \"f1: \",f1_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b298388",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bebac",
   "metadata": {},
   "source": [
    "# Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = pd.read_csv('files_for_lab/numerical.csv')\n",
    "categorical = pd.read_csv('files_for_lab/categorical.csv')\n",
    "target = pd.read_csv('files_for_lab/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e14767",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be15d7",
   "metadata": {},
   "source": [
    "#### Quickly calculating mean donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(target[target['TARGET_B']==1]['TARGET_D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1c106",
   "metadata": {},
   "source": [
    "# Ordinal categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3e4d09",
   "metadata": {},
   "source": [
    "It seem, that some of the values in the numerical df are in fact categorical.\n",
    "Nevertheless, I will leave them in the numerical dataframe, they are already represented as numbers, so there is no ordinal encoding neccessary.\n",
    "In addition they will get scaled this way and be in the same range as the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627eee1b",
   "metadata": {},
   "source": [
    "# Changing the datatype of the categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f867bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of the categoricals are still encoded as numbers, we change that, since otherwise they will get \n",
    "# missasigned in the num-cat-split\n",
    "\n",
    "# for i in categorical.columns:\n",
    "#     print(categorical[i].dtypes)\n",
    "\n",
    "\n",
    "# We only leave DOMAIN_B out, since they are already numbers in the right order and we would later ordinal encode them,\n",
    "# we will just assign them to the numerical dataframe, following the same logic as the other ordinal values.\n",
    "numerical['DOMAIN_B'] = categorical['DOMAIN_B']\n",
    "categorical =categorical.drop('DOMAIN_B', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "for col in categorical.columns:\n",
    "    categorical[col] = categorical[col].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now they are all objects\n",
    "\n",
    "# for i in categorical.columns:\n",
    "#     print(categorical[i].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6e4f1",
   "metadata": {},
   "source": [
    "# X-Y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([numerical,categorical], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5105dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_all = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.drop('TARGET_D', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11544a",
   "metadata": {},
   "source": [
    "# Num-Cat Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668144b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num  = X_train.select_dtypes(include = np.number)\n",
    "train_cat = X_train.select_dtypes(include = object)\n",
    "\n",
    "test_num  = X_test.select_dtypes(include = np.number)\n",
    "test_cat = X_test.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab724e",
   "metadata": {},
   "source": [
    "# Encoding and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9171f5",
   "metadata": {},
   "source": [
    "## Scaling the numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Fitting scaler\n",
    "transformer = MinMaxScaler().fit(train_num)\n",
    "# Scaling train and test data\n",
    "train_num_scaled = pd.DataFrame(transformer.transform(train_num), columns = train_num.columns, index = train_num.index)\n",
    "test_num_scaled = pd.DataFrame(transformer.transform(test_num), columns = test_num.columns, index = test_num.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093fea9",
   "metadata": {},
   "source": [
    "## OneHot encoding categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f54240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Fit encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore').fit(train_cat)\n",
    "# Getting the column names for the later selection\n",
    "column_name = encoder.get_feature_names_out(train_cat.columns)\n",
    "# Encode train and test\n",
    "train_encoded = pd.DataFrame(encoder.transform(train_cat).toarray(),columns = column_name, index=train_cat.index)\n",
    "test_encoded = pd.DataFrame(encoder.transform(test_cat).toarray(),columns = column_name, index=test_cat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b260f3e",
   "metadata": {},
   "source": [
    "# Concatenating prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.concat([train_encoded, train_num_scaled, y_train['TARGET_B']], axis = 1)\n",
    "X_test = pd.concat([test_encoded,test_num_scaled], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec1a6b",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d919593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Splitting into majority and minority class, the 'yes' donors are the minority class.\n",
    "no = train_all[train_all['TARGET_B']==0]\n",
    "yes = train_all[train_all['TARGET_B']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c80313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample minority\n",
    "yes_oversampled = resample(yes, #<- sample from here\n",
    "                                    replace=True, #<- we need replacement, since we don't have enough data otherwise\n",
    "                                    n_samples = len(no),#<- make both sets the same size\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d05c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oversampled = pd.concat([no,yes_oversampled],axis=0)\n",
    "train_oversampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09415e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = train_oversampled.drop('TARGET_B', axis = 1)\n",
    "y_train_over = train_oversampled['TARGET_B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43603dd3",
   "metadata": {},
   "source": [
    "# Testing Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd386f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classifier\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the classifier\n",
    "clf.fit(X_train_over, y_train_over)\n",
    "# Making predictions for outcome\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(confusion_matrix(y_test, y_pred))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86929d81",
   "metadata": {},
   "source": [
    "The result shows, that we are able to predict over half of the donors, but to achieve this, we send out a lot of letters, we will definately have to improve that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c08a9",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149272ad",
   "metadata": {},
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046c0a6",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "### Somesthing seems to went wrong when saving the pickle while trying to run this over night\n",
    "I can't get it to work again, will try something else and revisit this part later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa6a2e",
   "metadata": {},
   "source": [
    "In the last lab I tried PCA, Kbest and Variance selection.\n",
    "This time I will try with recursive feature elimination. The only obstacle might be, that \n",
    "with the number of columns it will tale long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm = linear_model.LogisticRegression()\n",
    "# rfe = RFE(lm, n_features_to_select=30, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fa05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# rfe.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ba320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes 1h 24min when opening the notebook we will continue with the pickled version!\n",
    "# pickle.dump(rfe, open('rec_feat_elim.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the pickled transformer\n",
    "# rfe = pickle.load(open('rec_feat_elim.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a65ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A lot of 'cluster' columns are in the resulting dataframe\n",
    "# df = pd.DataFrame(data = rfe.ranking_, columns=['Rank'])\n",
    "# df['Column_name'] = pd.DataFrame(X_train_over).columns\n",
    "# df[df['Rank']==1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transforming the data and trying out models:\n",
    "# X_train_rfe = rfe.transform(X_train_over)\n",
    "# X_test_rfe = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We try out the randeom forest with cross validate:\n",
    "# clf.fit(X_train_rfe, y_train_over)\n",
    "# results = cross_validate(model,X_test_rfe, y_test, cv = 5)\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f46080",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e598014",
   "metadata": {},
   "source": [
    "#### Kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b87502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest , chi2\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we do a quick transformation and see if we achieve anything this way\n",
    "model = SelectKBest(chi2, k=35).fit(X_train_over, y_train_over)\n",
    "XTr_temp = pd.DataFrame(model.transform(X_train_over), index = X_train_over.index)\n",
    "Xte_temp = pd.DataFrame(model.transform(X_test), index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(XTr_temp,Xte_temp,y_train_over, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c483336",
   "metadata": {},
   "source": [
    "#### Multicollinearity reduction\n",
    "We will have to eliminate multicollinearity and repeat the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reuse the function from yesterday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d55ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_check(model, df_input, number_of_columns):\n",
    "    # Making a dataframe of the scores and column names\n",
    "    df = pd.DataFrame(data = model.scores_, columns = ['score'])\n",
    "    df['Column'] = df_input.columns\n",
    "    # Sort it\n",
    "    df_sorted = df.sort_values(by = ['score'], ascending = False).reset_index()\n",
    "    # Making a list of the first x columns\n",
    "    collist = []\n",
    "    for i in range(number_of_columns):\n",
    "        collist.append(df_sorted['Column'][i])\n",
    "    # creating a correlation matrix\n",
    "    correlations_matrix = df_input[collist].corr()\n",
    "    correlations_matrix\n",
    "    # create a heatmap of it\n",
    "    plt.figure(figsize = (16,16))\n",
    "    sns.heatmap(correlations_matrix, annot=True, fmt='.2f')\n",
    "    plt.show()\n",
    "    return collist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951704d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = corr_check(model,X_train_over, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d40f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe is really long.\n",
    "# To eliminate multicollinearity, I would look for high correlation, \n",
    "# keep the first column(with the highest score) and eliminate those,\n",
    "# with a too high correlation with it.\n",
    "# I will try to put this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicor_elim(df):\n",
    "    '''\n",
    "    Iterating over the whole dataframe and eliminating multicollinearity by hand is tedious and not very effective\n",
    "    This function will iterate over the upper triangle of a correlation matrix and list the columns with a correlation\n",
    "    over a given threshhold.\n",
    "    '''\n",
    "    droplist = []\n",
    "    for row in range(len(df)):\n",
    "        # If the selected columns already is part of the droplist, further colinearity is not importand and we don't want\n",
    "        # to needlessly eliminate columns\n",
    "        if df.columns[row] in droplist:\n",
    "            pass\n",
    "        \n",
    "        # Since we iterate over the columns, starting with the row number, we just iterate over the upper triangle.\n",
    "        for col in range(row,len(df.columns)): \n",
    "            # We skip the comparison if we are in the diagonal. Otherwise we would eliminate all columns.\n",
    "            if row == col:\n",
    "                 pass\n",
    "            # We dont want to add columns multiple times\n",
    "            elif df.columns[col] in droplist:\n",
    "                pass\n",
    "            # Finally we can check for multicollinearity\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7fec23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2728d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffc939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05878ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic columns to remove:\n",
    "droplist = ['FIRSTDATE_YR_96','LASTDATE_YR_96','HVP1','FIRSTDATE_YR_86','HVP1','HVP3','HVP6','HVP4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the columns\n",
    "X_train_over = X_train_over.drop(droplist,axis=1)\n",
    "# We have to do the same for the test data\n",
    "X_test = X_test.drop(droplist,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again\n",
    "model = SelectKBest(chi2, k=35).fit(X_train_over, y_train_over)\n",
    "XTr_temp = pd.DataFrame(model.transform(X_train_over), index = X_train_over.index)\n",
    "Xte_temp = pd.DataFrame(model.transform(X_test), index = X_test.index)\n",
    "model_test(XTr_temp,Xte_temp,y_train_over, y_test)\n",
    "collist = corr_check(model,X_train_over, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic columns to remove:\n",
    "droplist = ['STATE_CA','RP1']\n",
    "# We drop the columns\n",
    "X_train_over = X_train_over.drop(droplist,axis=1)\n",
    "# We have to do the same for the test data\n",
    "X_test = X_test.drop(droplist,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ded21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again\n",
    "model = SelectKBest(chi2, k=35).fit(X_train_over, y_train_over)\n",
    "XTr_temp = pd.DataFrame(model.transform(X_train_over), index = X_train_over.index)\n",
    "Xte_temp = pd.DataFrame(model.transform(X_test), index = X_test.index)\n",
    "model_test(XTr_temp,Xte_temp,y_train_over, y_test)\n",
    "collist = corr_check(model,X_train_over, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e340ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic columns to remove:\n",
    "droplist = ['ODATEW_YR_86','ODATEW_YR_88']\n",
    "# We drop the columns\n",
    "X_train_over = X_train_over.drop(droplist,axis=1)\n",
    "# We have to do the same for the test data\n",
    "X_test = X_test.drop(droplist,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again\n",
    "model = SelectKBest(chi2, k=35).fit(X_train_over, y_train_over)\n",
    "XTr_temp = pd.DataFrame(model.transform(X_train_over), index = X_train_over.index)\n",
    "Xte_temp = pd.DataFrame(model.transform(X_test), index = X_test.index)\n",
    "model_test(XTr_temp,Xte_temp,y_train_over, y_test)\n",
    "collist = corr_check(model,X_train_over, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3609dc",
   "metadata": {},
   "source": [
    "As we can see, we have no more concerning multicollinearity in here and the amount of money our action would bring in got up quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These features look good, we will create a dataframe with jzust them and then move on:\n",
    "X__train_selected = X_train_over[collist].copy()\n",
    "X__test_selected = X_test[collist].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dba772",
   "metadata": {},
   "source": [
    "# Model pipeline\n",
    "We got the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different models\n",
    "model1 = LogisticRegression(random_state=0, solver='sag')\n",
    "model2 = DecisionTreeClassifier(max_depth=2)\n",
    "model3 = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.2 )\n",
    "model4 = neighbors.KNeighborsClassifier(n_neighbors=3, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over each model, apllying it with cross validation and returning the results for comparison.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model_pipeline = [model1, model2, model3, model4]\n",
    "model_names = ['Logistic Regressor', 'Decision Tree', 'Random Forest', 'KNN Classifier']\n",
    "scores = {}\n",
    "for model, model_name in zip(model_pipeline, model_names):\n",
    "    mean_score = np.mean(cross_val_score(model, X__test_selected, y_test, cv=10, scoring='recall'))\n",
    "    scores[model_name] = mean_score\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c48d66",
   "metadata": {},
   "source": [
    "Well as we know this still looks bad, hopefully the hyperparameter search will yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7d002",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae7a2df",
   "metadata": {},
   "source": [
    "#### Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8324dbd",
   "metadata": {},
   "source": [
    "We try to improve our Random Forest model with Hyperparameter tuning, since we had the best results with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier(\n",
    "#     n_estimators=100,\n",
    "#     *,\n",
    "#     criterion='gini',\n",
    "#     max_depth=None,\n",
    "#     min_samples_split=2,\n",
    "#     min_samples_leaf=1,\n",
    "#     min_weight_fraction_leaf=0.0,\n",
    "#     max_features='sqrt',\n",
    "#     max_leaf_nodes=None,\n",
    "#     min_impurity_decrease=0.0,\n",
    "#     bootstrap=True,\n",
    "#     oob_score=False,\n",
    "#     n_jobs=None,\n",
    "#     random_state=None,\n",
    "#     verbose=0,\n",
    "#     warm_start=False,\n",
    "#     class_weight=None,\n",
    "#     ccp_alpha=0.0,\n",
    "#     max_samples=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62273c76",
   "metadata": {},
   "source": [
    "These are the possible parameters for the random forest, I will do some research and find useful values to get into the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71438f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining what we want to try out\n",
    "grid = {\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split' : [2,5,100],\n",
    "            'n_jobs' : [-1],\n",
    "            'max_features' : ['sqrt',30],\n",
    "            'class_weight': [None,'balanced']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78938b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing random forest\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79389",
   "metadata": {},
   "outputs": [],
   "source": [
    "X__test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad094b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = 5, n_jobs = -1)\n",
    "# grid_search.fit(X__test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c05a7",
   "metadata": {},
   "source": [
    "The grid search took quite long, so I put the results here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    " class_weight= None,\n",
    " criterion= 'gini',\n",
    " max_depth= 5,\n",
    " max_features= 'sqrt',\n",
    " min_samples_split= 2,\n",
    " n_jobs= -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X__train_selected, y_train_over)\n",
    "predictions = rf.predict(X__test_selected)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(moneycalc(confusion_matrix(y_test, predictions)))\n",
    "print(\"Random Forest score: \", rf.score(X__test_selected, y_test))\n",
    "print(\"Random Forest precision: \",precision_score(y_test,predictions))\n",
    "print(\"Random Forest recall: \",recall_score(y_test,predictions))\n",
    "print(\"Random Fores f1: \",f1_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968b937",
   "metadata": {},
   "source": [
    "We get a relatively good amount of money on this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1bac3",
   "metadata": {},
   "source": [
    "# Additional tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836736a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to improve the reults by altering the probability threshhold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probpred(probabilities, threshhold):\n",
    "    predictions = []\n",
    "    # We create our own predictions list, if the probability is bigger than the threshhold,\n",
    "    # we set the value in our list.\n",
    "    for p in probabilities:\n",
    "        if p[1] >= threshhold:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5dfca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53408305",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probpred(rf.predict_proba(X__test_selected), .47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "print('Profit: '+str(moneycalc(cm))+ ' $')\n",
    "print(\"Random Forest score: \", rf.score(X__test_selected, y_test))\n",
    "print(\"Random Forest precision: \",precision_score(y_test,predictions))\n",
    "print(\"Random Forest recall: \",recall_score(y_test,predictions))\n",
    "print(\"Random Fores f1: \",f1_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac27c9d",
   "metadata": {},
   "source": [
    "I get the best value for how much money the mailing action would make if I lower the probability\n",
    "threshhold to 47%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b9aca",
   "metadata": {},
   "source": [
    "# Predictions for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9db24",
   "metadata": {},
   "source": [
    "#### Rebuilding the original dataframe, but already encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding the encoded dataframe\n",
    "df_1 = pd.concat([train_encoded, train_num_scaled, y_train], axis = 1)\n",
    "df_2 = pd.concat([test_encoded,test_num_scaled, y_test_all], axis = 1)\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1,df_2], axis = 0)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325ea8f",
   "metadata": {},
   "source": [
    "#### Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d644d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probpred(rf.predict_proba(df[collist]), .47)\n",
    "df['Predicted_B'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50724424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54957e42",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Takes quite some time, therefore commented out\n",
    "# df.to_csv('encoded_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350facf4",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a075aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost for all mailings:\n",
    "Cost = len(df[df['Predicted_B']==1])*0.68\n",
    "Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6421c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue\n",
    "Revenue = len( df[ (df['Predicted_B']==1) & (df['TARGET_B']==1)] ) * 15.62\n",
    "Revenue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449dc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue - Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309f1a2",
   "metadata": {},
   "source": [
    "Following the predictions the profit on our mailing action would be 19099 USD, \n",
    "this is already a substantial improvement in comparison to the about 11000 USD from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054b492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
